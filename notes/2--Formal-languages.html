<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<title>Formal languages</title>
<meta name="author" content="(Mark Armstrong)"/>
<meta name="description" content="Definition and tools for building formal languages.
Introduction to semantics."/>
<style type="text/css">
.underline { text-decoration: underline; }
</style>
<link rel="stylesheet" href="./reveal.js/dist/reveal.css"/>

<link rel="stylesheet" href="./reveal.js/dist/theme/black.css" id="theme"/>

<link rel="stylesheet" href="local.css"/>

<!-- If the query includes 'print-pdf', include the PDF print sheet -->
<script>
    if( window.location.search.match( /print-pdf/gi ) ) {
        var link = document.createElement( 'link' );
        link.rel = 'stylesheet';
        link.type = 'text/css';
        link.href = './reveal.js/css/print/pdf.css';
        document.getElementsByTagName( 'head' )[0].appendChild( link );
    }
</script>
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<style>pre.src{background:#000000;color:white;} </style>
<style>pre.src{background:#000000;color:white;} </style>
</head>
<body>
<div class="reveal">
<div class="slides">
<section id="sec-title-slide"><h2 class="title">Formal languages</h2>
   <h3>Principles of Programming Languages</h3>
   <h4>Mark Armstrong</h4>
   <h5>Fall 2020</h5>
</section>

<section>
<section id="slide-Preamble">
<h2 id="Preamble"><span class="section-number-2">1</span> Preamble</h2>
<p>
This section introduces the mathematical tools
we will use in the discussion of programming languages
as a <i>formal</i> language.
</p>

<p>
Several small formal languages (not full programming languages)
are used as examples of the use of these tools.
</p>

</section>
<section id="slide-Table-of-contents">
<h3 id="Table-of-contents"><span class="section-number-3">1.1</span> Table of contents</h3>
<font size="-1">
<div class="scriptsize">
<ul>
<li><a href="#/slide-Preamble">Preamble</a>
<ul>
<li><a href="#/slide-Table-of-contents">Table of contents</a></li>
<li><a href="#/slide-Notable-references">Notable references</a></li>
<li><a href="#/slide-Version-history">Version history</a>
<ul>
<li><a href="#/slide-September-23rd">September 23rd</a></li>
<li><a href="#/slide-September-21st">September 21st</a></li>
<li><a href="#/slide-September-16th">September 16th</a></li>
<li><a href="#/slide-Beginning-of-course">Beginning of course</a></li>

</ul></li>

</ul></li>
<li><a href="#/slide-Formal-languages">Formal languages</a>
<ul>
<li><a href="#/slide-The-usefulness-of-formal-languages">The usefulness of formal languages</a></li>
<li><a href="#/slide-Strings">Strings</a></li>

</ul></li>
<li><a href="#/slide-Describing-the-/syntax/-of-formal-languages">Describing the <i>syntax</i> of formal languages</a>
<ul>
<li><a href="#/slide-Regular-expressions-as-in-formal-language-theory">Regular expressions as in formal language theory</a></li>
<li><a href="#/slide-The-language-for-a-regular-expression">The language for a regular expression</a></li>
<li><a href="#/slide-Additional-operators-for-more-expressive-regular-expressions">Additional operators for more expressive regular expressions</a></li>
<li><a href="#/slide-Regular-expression-examples">Regular expression examples</a></li>
<li><a href="#/slide-Grammars-as-in-formal-language-theory">Grammars as in formal language theory</a></li>
<li><a href="#/slide-Notations-for-grammar-productions-in-formal-language-theory">Notations for grammar productions in formal language theory</a></li>
<li><a href="#/slide-Conventions-for-grammars">Conventions for grammars</a></li>
<li><a href="#/slide-A-simple-example-grammar">A simple example grammar</a></li>
<li><a href="#/slide-Exercise-–-reading-grammars">Exercise – reading grammars</a></li>
<li><a href="#/slide-Grammars-generate-or-recognise-strings">Grammars generate or recognise strings</a></li>
<li><a href="#/slide-Parse-trees">Parse trees</a></li>
<li><a href="#/slide-Example-parse-tree">Example parse tree</a></li>
<li><a href="#/slide-Another-example-parse-tree">Another example parse tree</a></li>
<li><a href="#/slide-Exercise:-creating-parse-trees">Exercise: creating parse trees</a></li>
<li><a href="#/slide-Backus-Naur-form-(BNF)">Backus-Naur form (BNF)</a></li>
<li><a href="#/slide-BNF-details">BNF details</a></li>
<li><a href="#/slide-Aside:-ALGOL">Aside: ALGOL</a></li>
<li><a href="#/slide-Extended-Backus-Naur-form-(EBNF)">Extended Backus-Naur form (EBNF)</a></li>
<li><a href="#/slide-EBNF-details">EBNF details</a></li>
<li><a href="#/slide-Exercise-–-translating-to-EBNF">Exercise – translating to EBNF</a></li>
<li><a href="#/slide-EBNF's-syntactic-sugar">EBNF's syntactic sugar</a></li>
<li><a href="#/slide-Exercise-–-a-small-language-C-like-language">Exercise – a small language C-like language</a></li>
<li><a href="#/slide-Example-–-EBNF-for-C++">Example – EBNF for C++</a></li>

</ul></li>
<li><a href="#/slide-Parsing-and-executable-code">Parsing and executable code</a>
<ul>
<li><a href="#/slide-Atomic-syntactic-units">Atomic syntactic units</a></li>
<li><a href="#/slide-Lexemes-and-tokens">Lexemes and tokens</a></li>
<li><a href="#/slide-Parsing">Parsing</a></li>
<li><a href="#/slide-The-zeroth-step-–-preprocessing">The zeroth step – preprocessing</a></li>
<li><a href="#/slide-The-first-step-–-lexical-analysis">The first step – lexical analysis</a></li>
<li><a href="#/slide-The-second-step-–-parsing-(syntactic-analysis)">The second step – parsing (syntactic analysis)</a></li>
<li><a href="#/slide-The-third-step-–-(static)-semantic-analysis">The third step – (static) semantic analysis</a></li>
<li><a href="#/slide-The-fourth-step-–-intermediate-code-generation">The fourth step – intermediate code generation</a></li>
<li><a href="#/slide-Visualising-the-entire-parsing-process">Visualising the entire parsing process</a></li>

</ul></li>
<li><a href="#/slide-Compilation,-interpretation,-and-hybrid-appraoches">Compilation, interpretation, and hybrid appraoches</a>
<ul>
<li><a href="#/slide-Compilation">Compilation</a></li>
<li><a href="#/slide-Interpreters">Interpreters</a></li>
<li><a href="#/slide-Hybrid-methods">Hybrid methods</a></li>

</ul></li>
<li><a href="#/slide-Ambiguity">Ambiguity</a>
<ul>
<li><a href="#/slide-An-example-of-ambiguity">An example of ambiguity</a></li>
<li><a href="#/slide-Removing-ambiguity">Removing ambiguity</a></li>
<li><a href="#/slide-Parentheses-make-structure-clear">Parentheses make structure clear</a></li>
<li><a href="#/slide-Enforcing-precedence-with-a-grammar">Enforcing precedence with a grammar</a></li>
<li><a href="#/slide-Enforcing-associativity-with-a-grammar">Enforcing associativity with a grammar</a></li>
<li><a href="#/slide-What-about-“associative”-operations?">“Associative” operations</a></li>
<li><a href="#/slide-Addition-is-not-associative…-in-some-cases">Addition is not associative… in some cases</a></li>

</ul></li>
<li><a href="#/slide-Abstract-and-concrete-syntax;-ignoring-ambiguity">Abstract and concrete syntax; setting ambiguity aside</a>
<ul>
<li><a href="#/slide-Abstract-syntax-trees-are-parse-trees.">Abstract syntax trees are parse trees.</a></li>
<li><a href="#/slide-We-are-interested-in-abstract-syntax">We are interested in abstract syntax</a></li>

</ul></li>
<li><a href="#/slide-The-/semantics/-of-formal-languages">The <i>semantics</i> of formal languages</a>
<ul>
<li><a href="#/slide-Semantic-domains">Semantic domains</a></li>
<li><a href="#/slide-Example-–-semantics-of-a-language-of-natural-numbers">Example – semantics of a language of natural numbers</a></li>
<li><a href="#/slide-Example-–-semantics-of-propositional-logic">Example – semantics of propositional logic</a></li>
<li><a href="#/slide-Example-–-small-step-semantics-of-propositional-logic">Example – small-step semantics of propositional logic</a></li>

</ul></li>

</ul>

</div>
</font>

</section>
<section id="slide-Notable-references">
<h3 id="Notable-references"><span class="section-number-3">1.2</span> Notable references</h3>
<ul>
<li>Benjamin Pierce,
“<a href="https://ebookcentral.proquest.com/lib/mcmu/detail.action?docID=3338823">Types and Programming Languages</a>”
<ul>
<li>Chapter 3, Untyped Arithmetic Expressions
<ul>
<li>Grammars. Alternative syntactic descriptions. Semantics.</li>

</ul></li>
<li>Chapter 5, The Untyped Lambda-Calculus
<ul>
<li>Abstract syntax.</li>

</ul></li>

</ul></li>

<li>Peter Van Roy and Seif Haridi,
“<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.102.7366&amp;rep=rep1&amp;type=pdf">Concepts, Techniques, and Models of Computer Programming</a>”
<ul>
<li>Section 2.1, Defining practical programming languages
<ul>
<li>Grammars. Alternative semantic approach (the kernel approach.)</li>

</ul></li>

</ul></li>

<li>Maribel Fernández,
“<a href="https://discovery.mcmaster.ca/iii/encore/record/C__Rb2200622?lang=eng">Programming Languages and Operational Semantics: A Concise Overview</a>” 
<ul>
<li>Section 1.3, Components of a Programming Language</li>

</ul></li>

<li>Robert W. Sebesta, “Concepts of Programming Languages” (10th edition)
<ul>
<li>Chapter 3, Describing Syntax and Semantics</li>
<li>Chapter 4, Lexical and Syntax Analysis</li>

</ul></li>

</ul>

</section>
<section id="slide-Version-history">
<h3 id="Version-history"><span class="section-number-3">1.3</span> Version history</h3>
</section>
<section id="slide-September-23rd">
<h4 id="September-23rd"><span class="section-number-4">1.3.1</span> September 23rd</h4>
<p>
Notes completed.
</p>

</section>
<section id="slide-September-21st">
<h4 id="September-21st"><span class="section-number-4">1.3.2</span> September 21st</h4>
<p>
More complete version posting. Nearly complete up to
Ambiguity.
</p>

</section>
<section id="slide-September-16th">
<h4 id="September-16th"><span class="section-number-4">1.3.3</span> September 16th</h4>
<p>
More complete version posted. Nearly complete up to Parsing.
</p>

<p>
After lecture, several typos fixed.
First parse tree example also fixed
(the nodes were in the wrong order.)
</p>

</section>
<section id="slide-Beginning-of-course">
<h4 id="Beginning-of-course"><span class="section-number-4">1.3.4</span> Beginning of course</h4>
<p>
Very incomplete version of the notes in place.
</p>

</section>
</section>
<section>
<section id="slide-Formal-languages">
<h2 id="Formal-languages"><span class="section-number-2">2</span> Formal languages</h2>
<p>
Recall, from formal language theory:
</p>

<p>
A language over an <i>alphabet</i> (set of symbols) \(Σ\)
is a subset of \(Σ^{*}\).
The elements of a language are called <i>sentences</i>
(or <i>strings</i> or sometimes <i>words</i>).
</p>

<p>
A <i>formal</i> language is one for which we have a mathematical tool
for either
</p>
<ul>
<li><i>generating</i> (or <i>deriving</i>) all sentences of the language,
or equivalently,</li>
<li><i>recognising</i> (or <i>accepting</i>) only sentences of the language.</li>

</ul>

<p>
Examples of such mathematical tools include
</p>
<ul>
<li>regular expressions,</li>
<li>automata, and</li>
<li>grammars.</li>

</ul>

</section>
<section id="slide-The-usefulness-of-formal-languages">
<h3 id="The-usefulness-of-formal-languages"><span class="section-number-3">2.1</span> The usefulness of formal languages</h3>
<p>
Formal languages, unlike <i>natural</i> languages, are well-suited
for comprehension by computers.
</p>
<ul>
<li>Machines require unambiguous steps to follow.</li>
<li>Hence, all programming languages are formal languages.</li>

</ul>

<p>
In particular, in most cases:
</p>
<ul>
<li>The sets of keywords, names, etc., form several <i>regular languages</i>,
and so can be recognised by regular expressions.</li>
<li>The set of valid (in terms of form) programs forms
a <i>context-free</i> language, and so can be recognised by
a (context-free) grammar.</li>

</ul>

</section>
<section id="slide-Strings">
<h3 id="Strings"><span class="section-number-3">2.2</span> Strings</h3>
<p>
Recall that given a set \(Σ\), the set of strings over \(Σ\),
written \(Σ^{*}\), is the set of all finite sequences
of elements of \(Σ\).
</p>

<p>
In particular, the sequence of length zero we denote by \(ε\).
Note that some other sources use \(λ\) for this purpose.
</p>

<p>
For example, for \(Σ = \{a, b, c\}\),
</p>
<div class="org-center">
<p>
\(Σ^{*} = \{ε, a, b, c, aa, ab, ac, ba, bb, bc, ca, cb, cc, aaa, …\}\).
</p>
</div>

<p>
Given an element \(e ∈ Σ\), we write
</p>
<ul>
<li>\(e^{n}\) for the string consisting of \(n\) occurrences of \(e\), and</li>
<li>\(e^{*}\) for the set \(\{ n ∈ ℕ ∣ e^{n} \}\).</li>

</ul>

</section>
</section>
<section>
<section id="slide-Describing-the-/syntax/-of-formal-languages">
<h2 id="Describing-the-/syntax/-of-formal-languages"><span class="section-number-2">3</span> Describing the <i>syntax</i> of formal languages</h2>
<p>
In this section, we will
</p>
<ul>
<li>briefly review regular expressions and grammars as
they are presented in formal language theory, and then</li>
<li>introduce more practical syntax for each
which is used in practice.</li>

</ul>

<p>
In both cases, the additional syntax only adds to
the <i>practical expressiveness</i> of the tool.
</p>
<ul>
<li>It does not change the tool's <i>theoretical expressiveness</i>.
<ul>
<li>The same set of languages can be described,
but many languages can be described “more easily”.</li>

</ul></li>
<li>We will present brief arguments to this effect
by showing how to translate from the new syntax
to the restricted syntax.</li>

</ul>

</section>
<section id="slide-Regular-expressions-as-in-formal-language-theory">
<h3 id="Regular-expressions-as-in-formal-language-theory"><span class="section-number-3">3.1</span> Regular expressions as in formal language theory</h3>
<p>
Given a finite alphabet \(Σ\),
the set of regular expressions (over \(Σ\)),
denoted \(RE(Σ)\), is given
by the following rules.
</p>
<ol>
<li>\(∅\), \(ε\) and \(a\) (for each \(a ∈ Σ\)) are regular expressions.</li>
<li>\((α | β)\), \((αβ)\) and \((α^{*})\) are regular expressions
<ul>
<li>for any regular expressions α and β.</li>

</ul></li>

</ol>

<p>
Respectively, the three operations in (2) are called
</p>
<ul>
<li>“or”,</li>
<li>“append”, and</li>
<li>“star” or “repeat”.</li>

</ul>

</section>
<section id="slide-The-language-for-a-regular-expression">
<h3 id="The-language-for-a-regular-expression"><span class="section-number-3">3.2</span> The language for a regular expression</h3>
<p>
The language generated/recognised by a regular expression
is defined via a (semantic) function \(L : RE(Σ) → Σ^{*}\),
defined as follows.
</p>
<ul>
<li>\(L(∅) = ∅\)</li>
<li>\(L(ε) = \{ ε \}\)</li>
<li>\(L(a) = \{ a \}\)</li>
<li>\(L(α | β) = L(α) ∪ L(β)\)</li>
<li>\(L(αβ) = \{ uv | u ∈ L(α) ∧ v ∈ L(β) \}\)</li>
<li>\(L(α^*) = (L(α))^*\)</li>

</ul>

</section>
<section id="slide-Additional-operators-for-more-expressive-regular-expressions">
<h3 id="Additional-operators-for-more-expressive-regular-expressions"><span class="section-number-3">3.3</span> Additional operators for more expressive regular expressions</h3>
<p>
Regular expressions come up frequently in programming,
and there is a rich set of extensions
to make them easier to construct.
</p>

<p>
We will not try to extensively list them, but some are listed below,
along with their equivalent “basic” form or,
where that is infeasible to write,
its language.
</p>
<ol>
<li>\(α^{+} \ \ \ ≈ \ \ \ αα^{*}\)</li>
<li>\(α? \ \ \ ≈ \ \ \ α | ε\)</li>
<li>\(\text{.} \ \ \ ≈ \ \ \ a | b | c | …\) where \(Σ = {a, b, c, …}\); i.e., \(L(.) = Σ\)</li>
<li>\([c_{1}…c_{n}] \ \ \ ≈ \ \ \ c_{1} | … | c_{n}\), where each \(c_{i}\) is a character.</li>
<li>\([\verb!^!c_{1}…c_{n}]\), where \(L([\verb!^!c_{1}…c_{n}]) = Σ - [c_{1}…c_{n}]\).</li>
<li>\(α\{m,n\}\), where \(L(α\{m,n\}) = ⋃_{i=m}^{n} L(α)^{i}\)</li>

</ol>

</section>
<section id="slide-Regular-expression-examples">
<h3 id="Regular-expression-examples"><span class="section-number-3">3.4</span> Regular expression examples</h3>
<p>
The set of all non-empty strings over the alphabet
can be described by this regular expression.
</p>
<ul>
<li>Note that if \(Σ\) includes whitespace characters,
this regular expression will allow strings made only of whitespace.</li>

</ul>
<div class="org-src-container">

<pre  class="src src-text"><code trim>.&#8314;
</code></pre>
</div>

<p>
The set of all non-empty strings which do not include
the letters <code>a</code>, <code>b</code> or <code>c</code> can be described by this regular expression.
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">[</span>^abc<span style="color: #00cd68;">]</span>&#8314;
</code></pre>
</div>

<p>
The set <code>{na,nana,banana}</code> can be described by
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">(</span>bana|na<span style="color: #00cd68;">)(</span>na<span style="color: #00cd68;">)</span>?
</code></pre>
</div>

</section>
<section id="slide-Grammars-as-in-formal-language-theory">
<h3 id="Grammars-as-in-formal-language-theory"><span class="section-number-3">3.5</span> Grammars as in formal language theory</h3>
<p>
Formally, a context-free grammar is a 4-tuple
</p>
<div class="org-center">
<p>
\(⟨N, Σ, P, S⟩\)
</p>
</div>
<p>
where
</p>
<ul>
<li>\(N\) is a finite set of <i>non-terminal</i> symbols
(sometimes called variables),</li>
<li>\(Σ\) is the underlying alphabet,
also called the <i>terminals</i> of the grammar,</li>
<li>\(N\) and \(Σ\) must be distinct,</li>
<li>\(P\) is a set of <i>productions</i> i.e.,
a binary relation between \(N\) and \((N ∪ Σ)^{*}\),
<ul>
<li>In other words, a multi-valued function from
nonterminals to strings of non-terminals and terminals,</li>

</ul></li>
<li>\(S\) is a distinguished element of \(N\), called the <i>starting nonterminal</i>.</li>

</ul>

</section>
<section id="slide-Notations-for-grammar-productions-in-formal-language-theory">
<h3 id="Notations-for-grammar-productions-in-formal-language-theory"><span class="section-number-3">3.6</span> Notations for grammar productions in formal language theory</h3>
<p>
Given
</p>
<div class="org-center">
<p>
\((A, α) ∈ P\),
</p>
</div>
<p>
we write
</p>
<div class="org-center">
<p>
\(A ⟶ α\)
</p>
</div>
<p>
and read it as
</p>
<div class="org-center">
<p>
“\(A\) produces \(α\)” or “\(A\) expands to \(α\)”.
</p>
</div>

<p>
Given a number of
productions
</p>
<div class="org-center">
<p>
\((A, α₁) ∈ P\), \((A, α₂) ∈ P\), …, \((A, αₘ) ∈ P\),
</p>
</div>
<p>
we write
</p>
<div class="org-center">
<p>
\(A ⟶ α₁ | α₂ | … | αₘ\)
</p>
</div>
<p>
as a shorthand.
</p>

</section>
<section id="slide-Conventions-for-grammars">
<h3 id="Conventions-for-grammars"><span class="section-number-3">3.7</span> Conventions for grammars</h3>
<p>
Writing the 4-tuple each time we produce a grammar is tedious.
</p>

<p>
For this reason, we adopt the following conventions
in order to allow us to omit the 4-tuple.
</p>
<ol>
<li>We write <i>only</i> the list of productions.</li>
<li>The set \(N\) is taken to be the set of all symbols
appearing to the left of a list of productions.
<ul>
<li>Note that this requires each nonterminal have
at least one production.</li>

</ul></li>
<li>The set \(Σ\) is usually understood by the context
in which we are defining the grammer.
<ul>
<li>For our purposes, it will usually be the set of
all ASCII symbols.</li>

</ul></li>
<li>The starting nonterminal \(S\) is understood to be either
<ol>
<li>the nonterminal whose name matches that of the grammar
we are defining (it may be uncapitalised or abbreviated),</li>
<li>otherwise, the non-terminal named \(S\), or</li>
<li>otherwise, the nonterminal to the left of
the first production in the list.
<ul>
<li>(We usually attempt to write grammars “top down”.)</li>

</ul></li>

</ol></li>

</ol>

</section>
<section id="slide-A-simple-example-grammar">
<h3 id="A-simple-example-grammar"><span class="section-number-3">3.8</span> A simple example grammar</h3>
<div class="org-src-container">

<pre  class="src src-text"><code trim>A &#10230; aAa | B
B &#10230; bBb | C
C &#10230; cCc | &#949;
</code></pre>
</div>

<p>
This produces the language of strings of
the form
</p>
<div class="org-center">
<p>
\(a^{i}b^{j}c^{k}c^{k}b^{j}a^{i}\)
</p>
</div>

</section>
<section id="slide-Exercise-–-reading-grammars">
<h3 id="Exercise-–-reading-grammars"><span class="section-number-3">3.9</span> Exercise – reading grammars</h3>
<p>
What languages do the following grammars produce?
</p>

<div class="org-src-container">

<pre  class="src src-text"><code trim>A &#10230; B | C
B &#10230; aaB | &#949;
C &#10230; aaaC | &#949;
</code></pre>
</div>

<div class="org-src-container">

<pre  class="src src-text"><code trim>A &#10230; aB | B | &#949;
B &#10230; bC | C
C &#10230; cA | A
</code></pre>
</div>

<div class="org-src-container">

<pre  class="src src-text"><code trim>A &#10230; aA | B
B &#10230; bB
</code></pre>
</div>

<p>
<b>What's the tricky part with the last one?</b>
</p>

<p>
Extra exercise: can you simplify any of them?
For instance, by having less non-terminals or less productions?
If you believe so, just be careful that
your simplification accepts the same string!
</p>

</section>
<section id="slide-Grammars-generate-or-recognise-strings">
<h3 id="Grammars-generate-or-recognise-strings"><span class="section-number-3">3.10</span> Grammars generate or recognise strings</h3>
<p>
We have discussed the facts that a grammar can
</p>
<ul>
<li>generate strings or</li>
<li>recognise/accept strings.</li>

</ul>

<p>
Then for a grammar \(G\) we might think of functions
</p>
<ul>
<li>\(generateᴳ : ℕ → Σ^{*}\)
<ul>
<li>with the intention that \(generateᴳ(n)\) generates the \(n^{th}\)
string in the grammar's language is lexicographic order</li>

</ul></li>
<li>\(recogniseᴳ : Σ^{*} → Bool\)</li>

</ul>
<p>
That is, we have two functions, which output a <code>String</code> or
a <code>Bool</code> respectively.
</p>

<p>
But there is a useful byproduct which may be obtained during
during either process: a <i>parse tree</i>.
</p>

</section>
<section id="slide-Parse-trees">
<h3 id="Parse-trees"><span class="section-number-3">3.11</span> Parse trees</h3>
<p>
A parse tree's
</p>
<ul>
<li>nodes (which have children) are
labelled by a nonterminal of the grammar,</li>
<li>leaves (which do not have children) are
labelled by a terminal of the grammar, and</li>
<li>if a node is labelled by a nonterminal <code>A</code>,
the children of that node must correspond to
(in order from left to right)
the terminals and nonterminals appearing in a production of <code>A</code>.
If a non-terminal would produce <code>ε</code>, it is omitted.</li>

</ul>

</section>
<section id="slide-Example-parse-tree">
<h3 id="Example-parse-tree"><span class="section-number-3">3.12</span> Example parse tree</h3>
<p>
For example, consider the grammar
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim>S &#10230; AB
A &#10230; aA | &#949;
B &#10230; Bb | b
</code></pre>
</div>

<p>
We have the following parse tree for the string <code>aab</code>.
</p>
<ul>
<li>Note the dashed portions, which show part of how the tree
was derived from the grammar,
but which will usually be omitted by our rules for parse trees.</li>

</ul>

<div class="figure">
<p><img src="media/parse-tree-example-aab.png" alt="parse-tree-example-aab.png" />
</p>
</div>

</section>
<section id="slide-Another-example-parse-tree">
<h3 id="Another-example-parse-tree"><span class="section-number-3">3.13</span> Another example parse tree</h3>
<p>
Similarly, working with the same grammar,
we have the following parse tree for <code>abb</code>.
</p>

<div class="figure">
<p><img src="media/parse-tree-example-abb.png" alt="parse-tree-example-abb.png" />
</p>
</div>

</section>
<section id="slide-Exercise:-creating-parse-trees">
<h3 id="Exercise:-creating-parse-trees"><span class="section-number-3">3.14</span> Exercise: creating parse trees</h3>
<p>
Exercise: provide a parse tree for the string <code>aaa</code> using this grammar.
Is there a valid parse tree for the string <code>bbb</code>?
</p>

<p>
Exercise: if we add a production <code>A ⟶ a</code> to our example grammar,
can you provide a different parse tree
(or multiple different parse trees) for <code>aaa</code>?
</p>

</section>
<section id="slide-Backus-Naur-form-(BNF)">
<h3 id="Backus-Naur-form-(BNF)"><span class="section-number-3">3.15</span> Backus-Naur form (BNF)</h3>
<p>
Up until now, we have used the form
</p>
<pre class="example">
N₁ ⟶ P₁ | P₂ | …
   ⋮
</pre>
<p>
for our production lists.
</p>

<p>
Commonly in the study of programming languages,
an alternative syntax called <i>Backus-Naur</i> form (BNF)
is used.
</p>
<ul>
<li>Named for two members of the ALGOL design committee,
who created the first formal definition for a programming language,
namely ALGOL.</li>

</ul>

</section>
<section id="slide-BNF-details">
<h3 id="BNF-details"><span class="section-number-3">3.16</span> BNF details</h3>
<p>
In Backus-Naur form,
</p>
<ul>
<li>all nonterminals names are delimited by
angle brackets, <code>⟨⟩</code>,
<ul>
<li>(if using ASCII characters, <code>&lt;&gt;</code>)</li>

</ul></li>
<li>the <code>⟶</code> is replaced by <code>∷=</code>,</li>
<li>additional whitespace is permitted on the right side
of a production between terminals and nonterminals,
without changing the meaning of the production
<ul>
<li>So \(⟨A⟩ ∷= a\ a\ ⟨A⟩\) is treated the same as \(⟨A⟩ ∷= aa⟨A⟩\).</li>

</ul></li>

</ul>

</section>
<section id="slide-Aside:-ALGOL">
<h3 id="Aside:-ALGOL"><span class="section-number-3">3.17</span> Aside: ALGOL</h3>
<p>
ALGOL (for “ALGOrithmic Language”)
was a contemporary of Fortran, Lisp, and Cobol.
</p>
<ul>
<li>Together, those three are the oldest languages
still in (fairly) common use today.
<ul>
<li>Granted, not the same versions.</li>

</ul></li>

</ul>

<p>
Specifically, there were several iterations of ALGOL,
the three major ones being ALGOL 58, ALGOL 60 and ALGOL 68.
</p>

<p>
ALGOL is not in common use, but it was
the most influential on modern programming language syntax,
introducing concepts such as the block.
</p>
<ul>
<li>The “C family” can trace its lineage directly to ALGOL.</li>

</ul>

</section>
<section id="slide-Extended-Backus-Naur-form-(EBNF)">
<h3 id="Extended-Backus-Naur-form-(EBNF)"><span class="section-number-3">3.18</span> Extended Backus-Naur form (EBNF)</h3>
<p>
We further extend our grammar notation to include several
several additional operators.
</p>
<ul>
<li>These extensions are part of the <i>extended</i> Backus-Naur form.</li>
<li>Once again, this is only an extension in the <i>practicality</i> sense.</li>

</ul>

<p>
There is an <a href="https://www.iso.org/standard/26153.html">ISO standard</a> for EBNF.
Our syntax and inclusion of features is
not chosen to match the standard;
it is what is convenient for our use.
</p>

</section>
<section id="slide-EBNF-details">
<h3 id="EBNF-details"><span class="section-number-3">3.19</span> EBNF details</h3>
<ul>
<li>(Square) brackets, <code>[]</code>, surrounding a string
indicate that string may or may not be included in a production.
<ul>
<li>I.e., they make part of a production optional.</li>
<li>\(⟨A⟩ ∷= α₁\ [\ α₂\ ]\ α₃\ \ \ \ ≈ \ \ \ ⟨A⟩ ∷= α₁\ α₂\ α₃\ |\ α₁\ α₃\).</li>

</ul></li>
<li>(Curly) braces, <code>{}</code>, surrounding a string
indicate that string may be repeated any number of times,
including zero.
<ul>
<li>\(⟨A⟩ ∷= α₁\ \{\ α₂\ \}\ α₃\ \ \ \ ≈ \ \ \ ⟨A⟩ ∷= α₁\ ⟨A′⟩\ α₃\), \(⟨A′⟩ ∷= α₂\ ⟨A′⟩\ |\ ε\).</li>

</ul></li>
<li>Parentheses, <code>()</code>, may group parts of a string.</li>
<li>The “alternative” pipe, <code>|</code>, may be used <i>inside</i> of productions,
to indicate alternatives inside a set of brackets, braces
or parentheses.
<ul>
<li>\(⟨A⟩ ∷= α₁\ (α₂\ |\ α₃)\ α₄ \ \ \ ≈ \ \ \ ⟨A⟩ ∷= α₁\ α₂\ α₄\ |\ α₁\ α₃\ α₄\).</li>

</ul></li>
<li>Where necessary, terminals may be single or double quoted,
such as to indicate a whitespace character, pipe or quote.
<ul>
<li>\(⟨\text{ebnfprods}⟩ ∷= ⟨\text{string}⟩\ |\ ⟨\text{string}⟩\ ⟨\text{optws}⟩\ “|”\ ⟨\text{optws}⟩\ ⟨\text{ebnfprods}⟩\)</li>

</ul></li>

</ul>

</section>
<section id="slide-Exercise-–-translating-to-EBNF">
<h3 id="Exercise-–-translating-to-EBNF"><span class="section-number-3">3.20</span> Exercise – translating to EBNF</h3>
<p>
Translate this grammar from an earlier exercise to EBNF syntax.
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim>A &#10230; B | C
B &#10230; aaB | &#949;
C &#10230; aaaC | &#949;
</code></pre>
</div>
<p>
Then try to reduce the number of productions in the grammar,
while maintaining the language defined.
</p>

<p>
Can you use only one production when using EBNF?
</p>

</section>
<section id="slide-EBNF's-syntactic-sugar">
<h3 id="EBNF's-syntactic-sugar"><span class="section-number-3">3.21</span> EBNF's syntactic sugar</h3>
<p>
EBNF and our extended regular expressions syntax
give us our first example of <i>syntactic sugar</i>;
syntax that does not add new features to a language,
only more convenient notation.
</p>
<ul>
<li>As shown above, any grammar using the additional operators
can be translated into one not using them.
<ul>
<li>But this likely requires more productions.</li>
<li>And certainly more characters/space on the page.</li>

</ul></li>

</ul>

<p>
Syntactic sugar is a common feature of programming languages.
</p>
<ul>
<li>Example: (imperative) languages often include various kinds of loops,
where only one (or sometimes none!) is truly necessary.</li>

</ul>

<p>
When we discuss programming languages formally,
we will usually omit constructs which are syntactic sugar.
</p>
<ul>
<li>If anything, we may note how to represent them
in a “core” language which includes less constructs.</li>

</ul>

</section>
<section id="slide-Exercise-–-a-small-language-C-like-language">
<h3 id="Exercise-–-a-small-language-C-like-language"><span class="section-number-3">3.22</span> Exercise – a small language C-like language</h3>
<p>
Consider the following context-free language.
</p>
<pre class="example">
⟨stmt⟩   ∷= ⟨assign⟩ | ⟨stmt⟩ "; " ⟨stmt⟩
⟨stmt⟩   ∷= "while " ⟨expr⟩ " do " ⟨stmt⟩ | ⟨ws⟩ ⟨stmt⟩ ⟨ws⟩
⟨assign⟩ ∷= ⟨var⟩ ⟨ws⟩ " := " ⟨expr⟩
⟨expr⟩   ∷= ⟨var⟩ | ⟨const⟩ | ⟨expr⟩ ⟨op⟩ ⟨expr⟩ | ⟨ws⟩ ⟨expr⟩ ⟨ws⟩
⟨var⟩    ∷= ('x' | 'y' | 'z') {⟨var⟩}
⟨const⟩  ∷= (1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0) {⟨const⟩}
⟨op⟩     ∷= '+' | '-' | '*' | '/' | '&lt;' | '&gt;' | '='
⟨ws⟩     ∷= {' '} | {'\n'}
</pre>

<p>
Provide some example programs in this language.
</p>

<p>
Can you precisely describe the language in English?
</p>

</section>
<section id="slide-Example-–-EBNF-for-C++">
<h3 id="Example-–-EBNF-for-C++"><span class="section-number-3">3.23</span> Example – EBNF for C++</h3>
<p>
A good example of the practicality EBNF for specifying
the syntax of languages is this
<a href="http://www.externsoft.ch/download/cpp-iso.html">EBNF grammar for C++</a>
(presented in tabular form, rather than lists of productions
as we use).
</p>

<p>
The grammar is much, much larger than anything we will write,
but it is still quite concise for describing
a real-world programming language.
</p>

</section>
</section>
<section>
<section id="slide-Parsing-and-executable-code">
<h2 id="Parsing-and-executable-code"><span class="section-number-2">4</span> Parsing and executable code</h2>
<p>
We will briefly summarise the parsing process,
beginning with some important terms.
</p>
<ul>
<li>In this course, we are primarily interested in
the beginning of this process, up to the
construction of parse trees.</li>

</ul>

</section>
<section id="slide-Atomic-syntactic-units">
<h3 id="Atomic-syntactic-units"><span class="section-number-3">4.1</span> Atomic syntactic units</h3>
<p>
We have mentioned that both regular expressions and
context-free grammars are used in the description of
the syntax of programming languages.
</p>

<p>
However, our example programming language earlier
was described exclusively by a context-free grammar.
</p>
<ul>
<li>Even the smallest syntactic units of the language,
the <i>atomic</i> syntactic units, have been described by the grammars.
<ul>
<li>For instance, we have used the production
\(⟨const⟩  ∷= (1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 0) \{⟨const⟩\}\)
which describes numerical constants.</li>

</ul></li>

</ul>

<p>
This is not done in practice.
</p>

</section>
<section id="slide-Lexemes-and-tokens">
<h3 id="Lexemes-and-tokens"><span class="section-number-3">4.2</span> Lexemes and tokens</h3>
<p>
In practice,
</p>
<ul>
<li>regular expressions are instead used to describe the
atomic syntactic units of languages.
<ul>
<li>For example,
<ul>
<li>keywords such as <code>if</code> and <code>while</code>, constant values such as <code>0</code> or <code>"abc"</code>,
or names such as <code>height</code> or <code>sqrt</code>.</li>

</ul></li>
<li>Lexemes cannot be broken down into meaningful pieces.</li>

</ul></li>
<li>Grammars are then used to describe the possible arrangements
of lexemes.
<ul>
<li>The terminals of the grammar are then names for sets of lexemes,
called <i>tokens</i>, rather than elements of \(Σ\).</li>
<li>For instance,
<ul>
<li>the token <code>while</code> for the set containing only the
keyword <code>while</code>,</li>
<li>or the token <code>int_literal</code> for the set \(\{ 0, 1, -1, 2, … \}\),</li>
<li>or the token <code>var</code> for the set of valid variable names.</li>

</ul></li>

</ul></li>

</ul>

</section>
<section id="slide-Parsing">
<h3 id="Parsing"><span class="section-number-3">4.3</span> Parsing</h3>
<p>
Parsing is the process of translating a program
from plaintext to executable instructions
</p>
<ul>
<li><p>
whether this is done
</p>
<ul>
<li>ahead of time (compiling) or</li>
<li>when the program is to be run (interpreting),</li>

</ul>
<p>
parsing is a necessary step before execution.
</p></li>
<li>A computer cannot run unparsed higher level language code.</li>

</ul>

</section>
<section id="slide-The-zeroth-step-–-preprocessing">
<h3 id="The-zeroth-step-–-preprocessing"><span class="section-number-3">4.4</span> The zeroth step – preprocessing</h3>
<p>
Many programming languages support some form
of <i>preprocessing directives</i> which are
to be carried out before the parsing process
properly begins.
</p>
<ul>
<li>Commonly, “macros”, which often are simply
textual substitutions to be carried out.
<ul>
<li>But they can be used for significantly more;
in some instances, these directives
form a programming language themselves.</li>

</ul></li>

</ul>

</section>
<section id="slide-The-first-step-–-lexical-analysis">
<h3 id="The-first-step-–-lexical-analysis"><span class="section-number-3">4.5</span> The first step – lexical analysis</h3>
<p>
After preprocessing, if it is present, comes the
the conversion of the plaintext source code
into a sequence of <i>tokens</i>.
</p>
<ul>
<li>This process may be
called <i>lexical analysis</i>, <i>lexing</i> or <i>tokenising</i>.</li>
<li>The program to carry this process out may be
called a <i>lexer</i> or <i>tokeniser</i>.</li>
<li>Lexical analysis discards whitespace, comments, and any other
text which is irrelevant to the machine.</li>

</ul>

</section>
<section id="slide-The-second-step-–-parsing-(syntactic-analysis)">
<h3 id="The-second-step-–-parsing-(syntactic-analysis)"><span class="section-number-3">4.6</span> The second step – parsing (syntactic analysis)</h3>
<p>
After converting from plaintext to a string of tokens, the next
step of parsing is to construct the parse tree.
</p>

<p>
This step is part of the parsing process,
but it is also usually called parsing.
</p>
<ul>
<li>It may also be called <i>syntactic analysis</i>.</li>

</ul>

<p>
More information about the program may be discarded here,
as the structure of the tree makes certain text
irrelevant (such as parentheses).
</p>

</section>
<section id="slide-The-third-step-–-(static)-semantic-analysis">
<h3 id="The-third-step-–-(static)-semantic-analysis"><span class="section-number-3">4.7</span> The third step – (static) semantic analysis</h3>
<p>
Once the parse tree is constructed,
rules about the form of programs
which cannot be (or cannot easily be)
described by a grammar are enforced
by <i>(static) semantic analysis</i>.
</p>

<p>
These rules include type checking and variable scope checking,
issues we will discuss later in the course.
</p>

<p>
This process produces the <i>symbol table</i>, which maps
each identifier to its relevant information,
such as
</p>
<ul>
<li>where it is declared in the source and</li>
<li>its type.</li>

</ul>

</section>
<section id="slide-The-fourth-step-–-intermediate-code-generation">
<h3 id="The-fourth-step-–-intermediate-code-generation"><span class="section-number-3">4.8</span> The fourth step – intermediate code generation</h3>
<p>
Most high-level languages are not translated directly to machine code;
instead, they are translated to some <i>intermediate code</i>,
which is closer to machine code than the high-level language.
</p>

<p>
For instance, languages on the JVM are translated
to Java bytecode during compilation/interpretation.
</p>

<p>
This intermediate code can then be translated
into machine code by later steps.
</p>

</section>
<section id="slide-Visualising-the-entire-parsing-process">
<h3 id="Visualising-the-entire-parsing-process"><span class="section-number-3">4.9</span> Visualising the entire parsing process</h3>

<div class="figure">
<p><img src="media/parsing-whole.png" alt="parsing-whole.png" />
</p>
</div>

</section>
</section>
<section>
<section id="slide-Compilation,-interpretation,-and-hybrid-appraoches">
<h2 id="Compilation,-interpretation,-and-hybrid-appraoches"><span class="section-number-2">5</span> Compilation, interpretation, and hybrid appraoches</h2>
<p>
We have mentioned above during the discussion of parsing
the notions of compilation and interpretation.
</p>

<p>
Let us define those terms.
</p>

</section>
<section id="slide-Compilation">
<h3 id="Compilation"><span class="section-number-3">5.1</span> Compilation</h3>
<p>
A <i>compiler</i> translates the whole program
(and any libraries or other code resources needed)
ahead of running it.
</p>
<ul>
<li>High upfront cost (time), for increased efficiency at runtime</li>
<li>Not portable; machine code is machine dependent.</li>

</ul>

</section>
<section id="slide-Interpreters">
<h3 id="Interpreters"><span class="section-number-3">5.2</span> Interpreters</h3>
<p>
An <i>interpreter</i> translates the program <i>as we are running it</i>.
</p>
<ul>
<li>No upfront cost, but less efficient.</li>
<li>Portable; can be run on any machine with an interpreter.
<ul>
<li>Alleviates some of the programmer's responsibility.
<ul>
<li>One user (or group) writes the interpreter <i>once</i>
(per machine type);
it can be used by any number of users for any number programs.</li>

</ul></li>

</ul></li>
<li>Efficiency is improved by using <b>just-in-time compilation</b>.
<ul>
<li>Store the result of interpretation so it can be used again.</li>

</ul></li>
<li>Can achieve better error reporting.
<ul>
<li>Relationship between original and translated codes is known at runtime.</li>
<li>This relationship is discarded when compiling code.</li>

</ul></li>

</ul>

</section>
<section id="slide-Hybrid-methods">
<h3 id="Hybrid-methods"><span class="section-number-3">5.3</span> Hybrid methods</h3>
<p>
<i>Hybrid methods</i> compile into a special intermediate language,
which is then interpreted into machine code when the program is run.
</p>
<ul>
<li>This intermediate language is usually similar to assembly.
<ul>
<li>But targets a virtual machine, not actual hardware!</li>

</ul></li>
<li>Usually called <i>bytecode</i>.</li>
<li>Greatly offsets efficiency cost of interpretation.</li>
<li>More portable than compiled code; just need
a bytecode interpreter for each target machine.</li>

</ul>

</section>
</section>
<section>
<section id="slide-Ambiguity">
<h2 id="Ambiguity"><span class="section-number-2">6</span> Ambiguity</h2>
<p>
We have discussed parse trees as a representation
of programs used during the parsing process.
</p>

<p>
Parse trees are extremely helpful because they allow us
to discard irrelevant details about program text,
and focus on the form of programs.
</p>

<p>
However, there is one significant problem which can occur:
what if a program has <b>multiple</b> parse trees?
</p>

<p>
It is desirable to have a single parse tree for every program.
</p>
<ul>
<li>We should not admit two syntactic interpretations for a program!</li>

</ul>

<p>
This can happen quite frequently, and we must discuss
methods of eliminating such <i>ambiguity</i>.
</p>

</section>
<section id="slide-An-example-of-ambiguity">
<h3 id="An-example-of-ambiguity"><span class="section-number-3">6.1</span> An example of ambiguity</h3>
<p>
For instance, the string <code>aa</code> has four valid parse trees
under the grammar
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">&#10216;</span>A<span style="color: #00cd68;">&#10217;</span> &#8759;= a <span style="color: #00cd68;">&#10216;</span>A<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>A<span style="color: #00cd68;">&#10217;</span> a | &#949; 
</code></pre>
</div>

<p>
Exercise: find all four valid parse trees for <code>aa</code> with the above
grammar.
</p>

</section>
<section id="slide-Removing-ambiguity">
<h3 id="Removing-ambiguity"><span class="section-number-3">6.2</span> Removing ambiguity</h3>
<p>
Three tools for removing ambiguity are
</p>
<ul>
<li>requiring parentheses,</li>
<li>introducing precedence rules, and</li>
<li>introducing associativity rules.</li>

</ul>

<p>
The first option takes the least work on the language designer's part.
</p>
<ul>
<li>But users of a language usually do not appreciate
“unnecessary” mandatory parenthesisation.</li>

</ul>

</section>
<section id="slide-Parentheses-make-structure-clear">
<h3 id="Parentheses-make-structure-clear"><span class="section-number-3">6.3</span> Parentheses make structure clear</h3>
<blockquote >

<div class="figure">
<p><img src="./media/comics/language.png" alt="language.png" />
</p>
</div>
</blockquote>
<p>
From the SMBC comic “<a href="http://smbc-comics.com/comic/language">Language</a>”
</p>

</section>
<section id="slide-Enforcing-precedence-with-a-grammar">
<h3 id="Enforcing-precedence-with-a-grammar"><span class="section-number-3">6.4</span> Enforcing precedence with a grammar</h3>
<p>
To enforce precedence using a grammar:
</p>
<ul>
<li>Create a hierarchy of non-terminals.</li>
<li>Higher-precedence operators are produced lower in the hierarchy.</li>
<li>For instance,
<ul>
<li>An additive term can be an addition of multiplicative terms,
which is a multiplication of atoms, which in turn are
either a constant, variable or a <b>parenthesised term</b>.</li>
<li>Note that there is recursion in the above,
but it's “guarded” with parentheses!</li>

</ul></li>

</ul>

<p>
For instance, if we call an additive term simply a <code>⟨term⟩</code> and
a multiplicative term a <code>⟨factor⟩</code>, we might have a grammar
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> &#8759;= <span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> + <span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> - <span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span>
<span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> &#8759;= <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> * <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> / <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>atom<span style="color: #00cd68;">&#10217;</span>
<span style="color: #00cd68;">&#10216;</span>atom<span style="color: #00cd68;">&#10217;</span> &#8759;= constant | variable | '<span style="color: #00cd68;">(</span>' <span style="color: #b6a0ff;">&#10216;</span>term<span style="color: #b6a0ff;">&#10217;</span> '<span style="color: #00cd68;">)</span>'
</code></pre>
</div>

</section>
<section id="slide-Enforcing-associativity-with-a-grammar">
<h3 id="Enforcing-associativity-with-a-grammar"><span class="section-number-3">6.5</span> Enforcing associativity with a grammar</h3>
<p>
To enforce associativity using a grammar:
</p>
<ul>
<li>Left associative operators should be produced by left recursive
non-terminals.</li>
<li>And right associative operators by right recursive non-terminals.</li>
<li>Operators of the same precedence must associate the same way!</li>

</ul>

<p>
For instance, to iterate on our previous example grammar,
we might write
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> &#8759;= <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> + <span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>term<span style="color: #00cd68;">&#10217;</span> - <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span>
<span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> &#8759;= <span style="color: #00cd68;">&#10216;</span>atom<span style="color: #00cd68;">&#10217;</span> * <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>factor<span style="color: #00cd68;">&#10217;</span> / <span style="color: #00cd68;">&#10216;</span>atom<span style="color: #00cd68;">&#10217;</span>
<span style="color: #00cd68;">&#10216;</span>atom<span style="color: #00cd68;">&#10217;</span> &#8759;= constant | variable | '<span style="color: #00cd68;">(</span>' <span style="color: #b6a0ff;">&#10216;</span>term<span style="color: #b6a0ff;">&#10217;</span> '<span style="color: #00cd68;">)</span>'
</code></pre>
</div>
<p>
Then <code>+</code> is right associative, <code>-</code> is left associative,
and similarly <code>*</code> is right associative and <code>/</code> is left associative.
</p>

</section>
<section id="slide-What-about-“associative”-operations?">
<h3 id="What-about-“associative”-operations?"><span class="section-number-3">6.6</span> “Associative” operations</h3>
<p>
You know that in mathematics,
we often avoid parentheses by declaring operations
to be <i>left associative</i> or <i>right associative</i>.
</p>
<ul>
<li>For a left associative operator <code>⊕</code>,
<code>a ⊕ b ⊕ c = (a ⊕ b) ⊕ c</code>.
<ul>
<li>Examples include subtraction.</li>

</ul></li>
<li>For a right associative operator <code>⊕</code>,
<code>a ⊕ b ⊕ c = a ⊕ (b ⊕ c)</code>.
<ul>
<li>Examples include exponentiation.</li>

</ul></li>
<li>An <i>associative</i> operator is a <code>⊕</code> for which
<code>a ⊕ b ⊕ c = (a ⊕ b) ⊕ c = a ⊕ (b ⊕ c)</code>.</li>

</ul>

<p>
But in computing, some operators behave differently than
their mathematical “selves”.
</p>

</section>
<section id="slide-Addition-is-not-associative…-in-some-cases">
<h3 id="Addition-is-not-associative…-in-some-cases"><span class="section-number-3">6.7</span> Addition is not associative… in some cases</h3>
<p>
Recall that addition is an associative operator.
</p>
<ul>
<li>So the choice of whether addition in a language associates to
the right or to the left may seem arbitrary.</li>
<li>But numerical types in programming are not necessarily
the same as numerical types in math!</li>
<li>Addition of floating point numbers <i>is not associative</i>.
<ul>
<li>Consider a binary representation with two-digit coefficients.</li>
<li>We will suffix the base with a subscript <code>b</code> to indicate
these are binary numbers.</li>
<li>\(1.0_{b} × 2^{0} + 1.0_{b} × 2^{0} + 1.0_{b} × 2^{2}\) has a different value depending
upon parenthesisation.</li>

</ul></li>

</ul>

<div class="org-center">
<p>
\((1.0_{b} × 2^{0} + 1.0_{b} × 2^{0}) + 1.0_{b} × 2^{2}\ \ =\ \ 1.0_{b} × 2^{1} + 1.0_{b} × 2^{2}\ \ =\ \ 1.1_{b} × 2^{2}\)
</p>
</div>

<div class="org-center">
<p>
\(1.0_{b} × 2^{0} + (1.0_{b} × 2^{0} + 1.0_{b} × 2^{2})\ \ =\ \ 1.0_{b} × 2^{0} + 1.0_{b} × 2^{2}\ \ =\ \ 1.0_{b} × 2^{2}\)
</p>
</div>

</section>
</section>
<section>
<section id="slide-Abstract-and-concrete-syntax;-ignoring-ambiguity">
<h2 id="Abstract-and-concrete-syntax;-ignoring-ambiguity"><span class="section-number-2">7</span> Abstract and concrete syntax; setting ambiguity aside</h2>
<p>
“Simple”, ambiguous grammars do have a place in describing
programming language syntax.
</p>
<ul>
<li>Such grammars describe the <i>abstract syntax</i> of the language.
<ul>
<li>As opposed to <i>concrete syntax</i>.</li>

</ul></li>
<li>Consider programs as <i>trees</i> generated by the grammar
for the abstract syntax of the language.
<ul>
<li>There may be ambiguity when translating a plaintext program to a tree.</li>
<li>But once a tree representation is chosen,
<b>there is no ambiguity</b>!
<ul>
<li>It may be that two different trees “flatten” to the same program,
but one tree cannot “flatten” to two different programs.</li>

</ul></li>
<li>Such trees more efficiently represent programs.
<ul>
<li>The shape of the tree expresses structure.</li>
<li>Other unnecessary details may be left out.</li>

</ul></li>

</ul></li>

</ul>

</section>
<section id="slide-Abstract-syntax-trees-are-parse-trees.">
<h3 id="Abstract-syntax-trees-are-parse-trees."><span class="section-number-3">7.1</span> Abstract syntax trees are parse trees.</h3>
<p>
We have already discussed how <i>parse trees</i> are used
as an internal representation of programs
after parsing.
</p>
<ul>
<li>We also stated that we discard irrelevant details during
lexical analysis and parsing (syntactic analysis.)
<ul>
<li>Such as whitespace, comments, and <b>during parsing</b>, parentheses!</li>

</ul></li>

</ul>

<p>
It is common to give two grammars for a language.
</p>
<ul>
<li>The concrete grammar describes the written form of programs.</li>
<li>The abstract grammar describes the internal representation of programs.</li>

</ul>

<p>
For this reason, <i>parse trees</i> are also called <i>abstract syntax trees</i> (ASTs.)
</p>

</section>
<section id="slide-We-are-interested-in-abstract-syntax">
<h3 id="We-are-interested-in-abstract-syntax"><span class="section-number-3">7.2</span> We are interested in abstract syntax</h3>
<p>
For the remainder of the course, we will focus on abstract syntax.
</p>

<p>
In particular, in the discussion of the semantics of formal languages,
concrete syntactic details are not of interest to us.
</p>

</section>
</section>
<section>
<section id="slide-The-/semantics/-of-formal-languages">
<h2 id="The-/semantics/-of-formal-languages"><span class="section-number-2">8</span> The <i>semantics</i> of formal languages</h2>
<p>
The <i>semantics</i> of a language assigns a meaning to each sentence.
</p>
<ul>
<li>In order to define a semantics, we must
have in mind a <i>semantic domain</i>;
<ul>
<li>a domain of meanings into which we map sentences.</li>

</ul></li>
<li>For instance, if we are defining a language
of natural numbers <i>Nat</i>, we will map sentences into the set <code>ℕ</code>.</li>
<li>Or map elements of a languages of propositions into <code>𝔹</code>.</li>
<li>We may often provide several different definitions of
a particular mapping, to emphasise different details.</li>

</ul>

</section>
<section id="slide-Semantic-domains">
<h3 id="Semantic-domains"><span class="section-number-3">8.1</span> Semantic domains</h3>
<p>
We may also have several semantic domains for a given language.
</p>
<ul>
<li>In the case of programming languages,
several domains of meaning have been proposed and used;
the three most well known are
<ul>
<li>computing devices, whether a real-world machine or an <i>abstract</i> machine,
<ul>
<li>this is known as <i>operational semantics</i></li>

</ul></li>
<li>(mathematical) functions,
<ul>
<li>this is known as <i>denotational semantics</i></li>

</ul></li>
<li>precondition/postcondition pairs
<ul>
<li>this is known as <i>axiomatic semantics</i></li>

</ul></li>

</ul></li>

</ul>

</section>
<section id="slide-Example-–-semantics-of-a-language-of-natural-numbers">
<h3 id="Example-–-semantics-of-a-language-of-natural-numbers"><span class="section-number-3">8.2</span> Example – semantics of a language of natural numbers</h3>
<p>
Consider a language of terms intended to represent
natural numbers.
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">&#10216;</span>nat<span style="color: #00cd68;">&#10217;</span> &#8759;= zero | suc <span style="color: #00cd68;">&#10216;</span>nat<span style="color: #00cd68;">&#10217;</span> 
</code></pre>
</div>

<p>
To assign meaning to these terms,
we introduce a mapping from these (concrete) terms
to (abstract) numerals.
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim>eval zero = 0
eval <span style="color: #00cd68;">(</span>suc n<span style="color: #00cd68;">)</span> = <span style="color: #00cd68;">(</span>eval n<span style="color: #00cd68;">)</span> + 1
</code></pre>
</div>

<p>
The evaluation function in this case is very obvious and trivial,
because this language is simply a concrete representation
of the semantic domain.
</p>
<ul>
<li>In comparison, when defining the semantics of programming languages,
the language and the semantic domain are not so directly related.</li>

</ul>

</section>
<section id="slide-Example-–-semantics-of-propositional-logic">
<h3 id="Example-–-semantics-of-propositional-logic"><span class="section-number-3">8.3</span> Example – semantics of propositional logic</h3>
<p>
As a more complex example, we can map propositional logic terms
into the set of booleans.
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim><span style="color: #00cd68;">&#10216;</span>prop<span style="color: #00cd68;">&#10217;</span> &#8759;= tt | ff | &#172; <span style="color: #00cd68;">&#10216;</span>prop<span style="color: #00cd68;">&#10217;</span> | <span style="color: #00cd68;">&#10216;</span>prop<span style="color: #00cd68;">&#10217;</span> <span style="color: #00cd68;">(</span>&#8743; | &#8744; | &#8658; | &#8660;<span style="color: #00cd68;">)</span> <span style="color: #00cd68;">&#10216;</span>prop<span style="color: #00cd68;">&#10217;</span>
</code></pre>
</div>

<p>
In order to make the mapping less trivial, let us define it
without using boolean combinators; only constants
and “if-then-else” statements.
</p>
<div class="org-src-container">

<pre  class="src src-text"><code trim>eval tt = true
eval ff = false

eval <span style="color: #00cd68;">(</span>&#172; p<span style="color: #00cd68;">)</span> = false   if eval p
             true    otherwise

eval <span style="color: #00cd68;">(</span>p &#8743; q<span style="color: #00cd68;">)</span> = eval q   if eval p
               false    otherwise

&#8230;
</code></pre>
</div>
<p>
Exercise: Complete this evaluation function.
</p>

</section>
<section id="slide-Example-–-small-step-semantics-of-propositional-logic">
<h3 id="Example-–-small-step-semantics-of-propositional-logic"><span class="section-number-3">8.4</span> Example – small-step semantics of propositional logic</h3>
<p>
The evaluation function defined above can be considered
to be a <i>big-step</i> semantics.
</p>
<ul>
<li>It is a (single-valued) relation between terms and
their (final) value.</li>

</ul>

<p>
In contrast, we may define a <i>small-step</i> semantics
</p>
<ul>
<li>which maps terms to terms which are “one step” simpler.</li>
<li>Then, once we have reduced to a constant term, that may be mapped
to a value (this part is not shown here).</li>

</ul>
<div class="org-src-container">

<pre  class="src src-text"><code trim>reduce <span style="color: #00cd68;">(</span>&#172; tt<span style="color: #00cd68;">)</span> = ff
reduce <span style="color: #00cd68;">(</span>&#172; ff<span style="color: #00cd68;">)</span> = tt
reduce <span style="color: #00cd68;">(</span>&#172; p<span style="color: #00cd68;">)</span>  = &#172; <span style="color: #00cd68;">(</span>reduce p<span style="color: #00cd68;">)</span>

reduce <span style="color: #00cd68;">(</span>tt &#8743; q<span style="color: #00cd68;">)</span> = reduce q
reduce <span style="color: #00cd68;">(</span>ff &#8743; q<span style="color: #00cd68;">)</span> = ff
reduce <span style="color: #00cd68;">(</span>p &#8743; q<span style="color: #00cd68;">)</span>  = <span style="color: #00cd68;">(</span>reduce p<span style="color: #00cd68;">)</span> &#8743; q

&#8230;
</code></pre>
</div>
<p>
Exercise: Complete this reduction function.
</p>
</section>
</section>
</div>
</div>
<script src="./reveal.js/dist/reveal.js"></script>
<script src="./reveal.js/plugin/markdown/markdown.js"></script>
<script src="./reveal.js/plugin/zoom/zoom.js"></script>
<script src="./reveal.js/plugin/notes/notes.js"></script>


<script>
// Full list of configuration options available here:
// https://github.com/hakimel/reveal.js#configuration
Reveal.initialize({
plugins: [RevealMarkdown,RevealZoom,RevealNotes],
width:1600, height:900, controlsLayout:'edges',
margin: 0.1, minScale:0.125, maxScale:5,
mouseWheel: true,
multiplex: {
    secret: '', // null if client
    id: '', // id, obtained from socket.io server
    url: '' // Location of socket.io server
},

// Optional libraries used to extend on reveal.js
dependencies: [
]
});
</script>
</body>
</html>
